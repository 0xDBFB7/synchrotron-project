## examples/xafs/doc_deconv4.lar
# while inotifywait -e close_write *.lar ../../larch/xafs/*.py; do larch --exec doc_deconv4.lar; done

import matplotlib.pyplot as plt
from numpy import genfromtxt
import scipy
#enguage digitizer
input_data = genfromtxt('./resolving_power/ZnS_theoretical_0_1eV_broadening.csv', delimiter=',', skip_header=1) # there's room for improvement on both traces
# print(np.shape(input_data))
energies = input_data[:,0]
# energies = np.concatenate((np.array([161, 161.5, 162]), energies))
theory = input_data[:,1]
experiment = input_data[:,2]

experiment -= experiment[0]

series = np.linspace(energies[0], energies[-1], 1000)
experiment = scipy.interpolate.interp1d(energies, experiment, kind='cubic', fill_value='extrapolate')(series)
theory = scipy.interpolate.interp1d(energies, theory, kind='cubic', fill_value='extrapolate')(series)
energies = series

# the dataset was padded with a tapered ramp.
# surprisingly dramatic example.
# this is a worst-case scenario as regards noise because these were manually digitized from graphs.
# convergence properties aren't right
# the stock deconvolution algorithm flatly refused to run for reasons which have not yet been determined.
# The first few indices of the deconvolved array are invalid.
# LR provides an unphysical shift.
# possible throughput advantages for exploratory research.

data = group(energy=energies,mu=experiment)

pre_edge(data, e0=162, pre1=162, pre2=162)

autobk(data, rbkg=1.1, kweight=2)
xftf(data, kmin=2, kmax=17, dk=5, kwindow='kaiser', kweight=2)


# data.mu = 


# data.mu = smooth(data.energy, data.mu, sigma=0.1)
# data.norm = smooth(data.energy, data.norm, sigma=0.1)


data.mu -= data.mu[0]
data.norm -= data.norm[0]

data.mu /= np.max(data.mu)

data.norm = data.mu

# plot(data.energy, data.norm, label='Original',  win=1)
sps = 5
plt.subplot(sps, 1, 1)
plt.plot(data.energy, data.norm)


# core_width('Zn', edge='L3')
xas_iterative_deconvolve(data, esigma=0.5, eshift=0.0, regularization_filter_width=0.05, max_iterations=3000, grid_spacing=0.005)

plt.subplot(sps, 1, 2)
plt.plot(data.energy[10:], data.deconv[10:], label='iterative_deconvolved')
plt.subplot(sps, 1, 3)
plt.plot(data.energy[10:], theory[10:], label='iterative_deconvolved')
# plot(np.arange(len(data.convergence)), log(data.convergence), label='Convergence',  win=2)

xas_deconvolve(data, esigma=0.7, smooth=True)
plt.subplot(sps, 1, 4)
plt.plot(data.energy[10:], data.deconv[10:], label='iterative_deconvolved')
# xas_deconvolve(data, esigma=0.5, smooth=False)
# with smooth=false, this doesn't work at all.

# theory = smooth(data.energy, theory, sigma=1.0) # representing figure 5 

plt.show()
input()
## end examples/xafs/doc_deconv3.lar
